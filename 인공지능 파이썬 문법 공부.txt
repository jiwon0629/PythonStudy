[ numpy란? ]  

Numpy는 C언어로 구현된 파이썬 라이브러리  
Numerical Python 줄임말  
고성능의 수치계산을 위해 제작  
벡터 및 행렬 연산에 효율적  

[ 논리 연산자 ]

AND
X1(입력2) | X2(입력2) | Y(출력)
   0          0          0
   1          0          0
   0          1          0
   1          1          1

OR
X1(입력2) | X2(입력2) | Y(출력)
   0          0          0
   1          0          1
   0          1          1
   1          1          1

NOT
X(입력) | Y(출력)
   0        1
   1        0

NAND
X1(입력2) | X2(입력2) | Y(출력)
   0          0          1
   1          0          1
   0          1          1
   1          1          0

XOR
X1(입력2) | X2(입력2) | Y(출력)
   0          0          0
   0          1          1
   1          0          1
   1          1          0

[ 다층퍼셉트론 ]

역전파 알고리즘
정방향으로 이루어지는 계산 이후에 역방향으로 간단하게 기울기를 찾는 방법이 고안됨

기울기 소실
계층이 깊어질수록 학습이 어려워지는 이유는 기울기 소실(Vanishing Gradient)이 발생하기 때문

[ 샘플링과 양자화 ]

양자화 : 그림의 색을 저장할 때 어느 정도의 정밀도를 가지게 저장할 것인지를 결정한다.
비트수에 따라 양자화의 정도가 결정된다.

샘플링 : 모든 입력값을 다 저장하는 것이 아니라 일정 간격으로 샘플을 모으고 모인 샘플을 사용하겠다는 것
서브 샘플링 : 이미지 픽셀의 값을 건너뛰면서 가져오는 것

[ 항등 함수 ]

항등 함수(identity function) : 입력을 그대로 출력으로 내보내는 것
f(x) = x

비례확률함수 : 일정한 값들이 들어왔을 때 그 값들을 크기의 비율로 쓴 것으로 총합이 1이 되게 만든 함수이다.
비례확률함수는 신경망에서 사용되지 않는다.

소프트맥스 함수 : 출력의 합은 1이 되면서 큰 값의 비중은 더 크게, 작은 값의 비중은 더 작게 만들어주는 특징을 가진다.
신경망에서 나오는 출력값을 보다 확실하게 하기 위해 원래의 값을 보정해서 확률로 만든 값이다.

[ 손실 함수 ]

정확도는 학습을 진행할 때 큰 의미를 부여하지 못한다. 
이유는 신경망의 결과와 정답의 차이를 보정해주지 못하기 때문이다. 
기울기를 찾을 수 없어서 학습하기 어렵기 때문에 최종 결과값이 아닌 확률값을 사용하고, 이것을 손실함수로 정의해서 사용한다.

평균, 기댓값
평균과 기댓값은 같은 내용을 다르게 표현하는 것.
평균 : 표본을 모두 더한 후 그 갯수로 나눈 것
기댓값 : 각 표본이 일어날 확률값에 표본의 값을 곱해서 전체에 대해 더한 것

중간값(median)
데이터를 일렬로 늘어놓았을 때 한 중앙에 위치하는 값
데이터의 대표값으로 많이 사용되는 것이 평균과 중간값이다.
데이터에 이상값이 많은 경우 중간값이 자주 사용된다.

표준편차, 분산
분산 : 전체의 데이터가 평균과 얼마나 멀리 떨어진 곳에 분포하는지를 나타내는 값
모든 데이터의 값에서 평균을 뺀 다음 제곱한 값의 평균
표준편차 : 분산에 제곱근을 씌워준 값

평균제곱오차(MSE; Mean Square Error) : 오차들의 제곱을 평균한 것


